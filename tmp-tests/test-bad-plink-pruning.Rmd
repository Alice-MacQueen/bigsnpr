---
title: "Why clumping should be prefered over pruning"
author: "Florian PrivÃ©"
date: "November 24, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this short document, I will show why clumping should be prefered over pruning for SNP arrays.

## Simulation

I generate a (toy) SNP array with 500 individuals and 10 SNPs, where each SNP has a squared correlation > 0.2 with its direct neighbours and only with them. Moreover, the SNPs have an increasing MAF.

```{r}

gen <- function(n, m) {
  I <- 1:m
  p <- I / (2 * m + 1)

  mat <- outer(I, I, FUN = function(i, j) {
    1 / (abs(i - j) + 1)
  })

  2 * bindata::rmvbin(n, p, bincorr = mat)
}

set.seed(1)
X <- gen(500, 10)
print(head(X))
print(round(cor(X)^2, 2)) # squared correlation between SNPs
print(colMeans(X) / 2) # MAF of SNPs
```

## Pruning

I then pseudo-convert the SNP matrix in my format `BigSNP` and use my reimplementation of PLINK pruning on this dataset (similar to `--indep-pairwise 10 1 0.2`)

## Results and conclusion

The first SNP is pruned because of its correlation with the second. The
second SNP is pruned because of its correlation with the third and so
on. In the end, only the last SNP (10th) is kept with the LD pruning
procedure of PLINK.

On the contrary, a clumping approach would consider the SNPs sorted
(in a decreasing order) by a statistic (here the MAF). So the last SNP
(10th) would be considered first and the 9th SNP would be pruned. Then the 8th SNP would be considered and the 7th SNP would be pruned and so on. So, the even SNPs would be kept and the odd SNPs would be pruned.

__Your choice?__
